---
title: Responsible Repositories 
authors:
  - name: Nathanael Sheehan
    department:  College of Engineering, Mathematics and Physical Sciences 
    affiliation: Exeter University
    location: University of Exeter, St Germans Road, EX4 7HD Exeter, UK
    email: ns651@exeter.ac.uk
  - name: Sabina Leonelli
    department: EGENIS, Centre For The Study Of Life Sciences
    affiliation: Exeter University
    location: University of Exeter, St Germans Road, EX4 7HD Exeter, UK
    email: s.leonelli@exeter.ac.uk
abstract: "Building on previous discussions on Epistemic diversity and Open Science, we demonstrate a novel metric system based on the description of Responsiblity from the TRUST data repositoiry principle (Lin et al 2020). We use two case studies from popular genomic survelience programs, GISAID and the Covid-19 Data Platform, to explore the naunces between interpetations of openesss, we link these discussions to ."
keywords:
  - SARS-CoV2
  - Open Science
  - Data Governance
bibliography: references.bib
biblio-style: unsrt
output: rticles::arxiv_article
always_allow_html: true

---

# Introduction

The pandemic collapsed normative scientific practices and demanded rapid, scalable and open access to the latest research findings, treatments and protocols on the coronavirus. This shift in research practice - in conjunction with decreasing costs in data storage - has led to an exponential increase in data repositories becoming publicly accessible online, as well as a global recognition of Open Science (OS) principles by the United Nations [REF]. Simultaneously, a wider discourse emerged among policy circles and researchers with concern to the responsibility of repositories reporting on COVID-19 and related topics, most evidently in relation to the prompt dissemination of genetic sequencing data from various strains of the SARS COV-2 virus [See inter alia @Meredith2020;@Romano2021;@Brito2021;@Kalia2021;@Harrison2021;@Romano2021]. 

On the 29th of January 2021 the governing board of the European Bioinformatics Institute (EBI) posted a public letter in Nature calling for a greater "openness" in sharing SARS-CoV-2 genome data, the letter argued "to unleash the fast flow of research advances" the scientific community must remove all formal barriers which restrict data sharing and share all SARS-CoV-2 genome sequences to one of a triad of state genomic surveillance programs (EBI, The GenBank of USA and the DNA Data Bank of Japan). The letter was exclusively signed and promoted by Nobel Laureates, Directors of Bioinformatic programs and many researchers at the cutting edge of genome sequencing. At the same time, the Global Initiative on Sharing Avian Influenza Data (GISAID) had just overtaken the EBI's European COVID-19 Data Portal (C19DP) in the volume of genome sequences being shared to open access databases (See appendix Figure 1). GISAID was launched in 2008 to monitor global influenza outbreaks and from the offset positioned itself as an alternative to the public domain sharing model (creative commons), instead GISAID formulated a policy which required users to authenticate their academic identity and agree not to republish the sites genomes without permission from the data producer. At the beginning of 2020, after receiving a number of philanthropic donations from the World Health Organization, big-pharma and nation states, GISAID launched the EpiCov database which stores, analyses and builds evolutionary trees of SARS COV-2 genome sequences. The platform is currently hosted by the German Institute of Agriculture and the Max Planck institute and continues to be the leading open access database, with over 9 million genomes being sequenced. 

Although the letter did not mention GISAID exclusively, this series of events brings together a clash in ideologies on what constitutes as responsible openness during a crisis. @pittphilsci19817 introduces this case study as a clash in "responsible research measures", pointing out how "trustworthy and explicitly non-exploitative conditions for data sharing helps to widen participation in data sharing", in this same line of thought we stipulate that Trust and Responsibility, or a lack of it, plays a central role in the success of OS platforms; hence researchers and data producers alike, must ensure quality and integrity of data when practicing OS principles in order to demonstrate the quality and discipline which OS research demands [@AZEROUAL2021169]. 

The TRUST (Transparency, Responsibility, User Focus, Sustainability, and Technology) principles put forth a set of guidelines to  demonstrate the trustworthiness of a digital repository to many of the stakeholders involved, including researchers, community users, funders, developers and service providers. In an OS context, a number of trustworthiness certification mechanisms already exist; The Open Archival Information System (OAIS) provides a recommendation model to provide long-term preservation and access to digital information [@lavoie2004open] and the FAIR principles emphasize a best practice of machine and human re-usability with data objects. However, Lin et al (2020) argue these frameworks are not suitable for a broader audience and lack a critical understanding of the temporal aspects of a data repository, data may enter a system under a FAIR or OAIS system, however TRUST should not be understood as a single check box, rather it must regularly audited to ensure the system ensures trust for the long run [@Lin2020. Repository users should have confidence that data depositors are prompted to provide all metadata compliant with the community norms, as this greatly enhances the discoverability and usefulness of the data. Knowing that a repository verifies the integrity of available data and metadata assures potential users that the data holdings are more likely to be interoperable with other relevant datasets. Both depositors and users must have confidence that the data will remain accessible over time, and thus can be cited and referenced in scholarly publications. 

# Methods

## Definition
Stakeholders of a repository must take responsibility - legally and ethically- for the data being stored and collected from their user community. Lin et al (2020) delineates responsibility being demonstrated as:

- "*Adhering to the designated community’s metadata and curation standards, along with providing stewardship of the data holdings e.g. technical validation, documentation, quality control, authenticity protection, and long-term persistence.*

- *Providing data services e.g. portal and machine interfaces, data download or server-side processing.*

- *Managing the intellectual property rights of data producers, the protection of sensitive information resources, and the security of the system and its content.*"

We classify our reading of responsibility into three distinct modes which are described by sub classifications metrics. Each metric varies on a scale from 0-1, where 0 indicates the responsibility classification is "not implemented", 0.4 indicates the responsibility classification is "partially implemented" and 0.9 indicates the responsibility classification is "Sufficiently implemented". The total score for each distinct mode is calculated as a mean weighted average from each of its sub classifications. A summary table can be found in table 1.
 
## Data Responsibility
Data Responsibility is the largest group of sub-classifications and focuses on the quality, re-usability and interoperability of data stored on the repository. `R1.1 Sufficient Metadata` asserts repository metadata conform to a general curation standard whereby data can be transformed for further discoverability and provides sufficent overviews of the data entering the platform. `R1.2 Technical Documentation` requires a closed reading of each repository 'docs', and evaluates whether the documents provide clear and useful instructions to successfully interact and use the platform. `R1.3 Format Control` concerns a format control test to ensure that users uploading data have to do so in a standardized form. `R1.4 Content Control` asks if user content goes under a form of peer review to ensure integrity of data producers. `R1.5 Authenticated Provinence` checks if there are forms of authentication in order to interact with the data repository. 

## Service Responsibility
Service Responsibility is the smallest group of sub-classifications and focuses on the tools presented to download and upload data. `R2.1 Reliable Data Services` tests the performance of tools made available to download data and further  if data can be downloaded in a range of formats and is machine readable. 


## Legal Responsibility
Legal Responsibility is a critical component to the R in trust as it binds the digital and physical world. `R3.1 Manage IP of Data Producers` verifies the intellectual property policy for data producers and the effects this has for both data producers and users of the platform. `R3.2 Security of System` studies the vulnerabilities in infrastructure which uphold the data, the platform and the various microservices which contribute to the functioning of the digital system. `R3.3 Security of Content` describes the measures taken by data stewards to ensure data producers content is not reshared or published without their permission. 

```{r fig1, fig.cap = "Table of Responsiblity Metric", echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
r_score = data.frame(matrix(ncol = 3, nrow = 5))

cols = c("Data Responsibility",
         "Service Responsibility",
         "Legal Responsibility")
colnames(r_score) = cols

mr = c(  "R1.1 Curated Metadata",
         # metadata which documents the progress of data in the repo to date
         "R1.2 Techincal Documentation",
         # documentation online on how to use data services
         "R1.3 Format Control",
         # uploading data
         "R1.4 Content Control",
         # peer review
         "R1.5 Authenticated Provinence")
r_score$`Data Responsibility` = mr

sr = c("R2.1 Reliable Data Services")
r_score$`Service Responsibility`[1] = sr

lr = c(  # LEGAL Responsibility
  "R3.1 Manage IP of Data Producers",
  # legal agreement much can be done
  "R3.2 Security of System",
  # does the system have vulnerabilities
  "R3.3 Security of Content" # how is content ensured its not reshared ?
  )
r_score$`Legal Responsibility`[1:3] = lr
r_score[is.na(r_score)] = ""   
kable(r_score, caption = "Modes of responsiblity and sub classifcations metrics") %>% kable_material_dark() %>%
  kable_styling(latex_options = "HOLD_position")

```

# Results

This sections outlines the justifications for each sub classification score per case study, the full results are summarised in table 2. 

## GISAID
Overall, GISAID outperforms the Covid-19 Data Portal using our responsibility metric method. Moreover, GISAID at least partially implements all responsibility sub classification measurements and performs best in the Data and Service Responsibility. However GISAID is far from perfect. GISAID's metadata 

### Data Responsibility 

#### R1.1 Sufficient Metadata 
The GISAID's EpiCov database partially implements a form of standardized metadata under the "Submission and Variant statistics" download option. GISAID aid offer five meta-datasets, three of which are Excel spreadsheets containing aggregated submissions per Country, US state or variant; these meta-datasets are packaged in a standard wide data format, which when transformed into a long data format contain three/four columns: "Country", "Date", "Count" and "Variant". In addition, GISAID provide metadata concerning the variant lineage/clade in two formats - table separate values (TSV) and JavaScript Object Notation (JSON) - where the number of submissions is broken down by "submissions per variant", "submissions per aa substitution", "submissions per lineage" and "submissions per clade". While this offers a building block in ensuring re-usability and interoperability, all of the meta-datasets miss out on potentially useful information which GISAID already stores for submissions, for example "Host", "Location" (at a higher spatial scale i.e city), "originating lab" and "submitting lab", for this reason GISAID accomplishes a partially implemented status as they are clear descripenecies in the designated community’s metadata.

#### R1.2 Techincal Documentation

GISAID does not provide any formal documentation on their platform, but this is not surprising, GISAID functions solely from the graphical user interface and does not provide any API or CLI interfaces. Instead GISAID provides two training videos and documents on protocols.io - an open access platform for sharing, discovering, and discussing scientific methods - to document versions of the submission process step by step. The quality of this documentation leads to a partial implementation score, as the protocols and videos are only available in English and despite the most recent protocol being the third version, it still looks unfinished; headings are missing, there are no concluding remarks and zero additional resources are supplied to assist in further interoperablity. 

#### R1.3 Format Control

GISAID clearly documents a format control for data producers to follow in order to submit sequences to the EpiCov database. This format is accessible on both the platform and on the protocol documents. Format control is clearly distinguished between mandatory and non mandatory fields and provides automated checks to assert submissions do not deviate from the existing format thus GISAID receives a sufficient implementation score.  

#### R1.4 Content Control

Peer review is currently unknown.

#### R1.5 Authenticated Provinence

One clear distinction between the two platforms is the requirement for data producers and users to register in order to access the GISAID database. 
GISAID requires users to confirm their identity and comply with GISAID's policy to not republish data without permission from the data producer and is the clearest distrinction between the two platforms openess philopsohies. Authentication to the GISAID platform takes between a few hours to several days and consists of seven "Personal Data" questions (*Title, Salutation, First Name, Middle Name, Last Name, Title, Desired Login*) and eleven "Contact information" questions (*Institution, Department, Street, Postal Code, City, Location, State/province, Telephone, Fax, Mobile, Email*). This simple, known and effective process determines a sufficent implementation score.   

### Service Responsibility

#### R2.1 Reliable Data Services

As previously mentioned, GISAID's download and upload services function through a GUI on the platforms website. Sequences are downloaded using the "Alignment and proteins" download option which operates by calling an internal function to trigger a data download, this implementation provides a fast download service when the page is active and the download page scores a 92 in performance by PageSpeed Insights. 

### Legal Responsibility

#### R3.1 Manage IP of Data Producers

The GISAID EpiCov Database utilizes a proprietary platform and software technology which is owned by GISAID and/or third party contractors, yet an explicit set of rules that govern the intellectual property of data producers is logged in clause `g` of the GISAID database access agreement. Data producers are expected to obtain the necessary authorization or license in order to share data on GISAID and must agree not to impose any further terms on the data which may alter or restrict further data sharing. Moreover, data producers should not reverse engineer or disclose any part of the database platform publiclly, as well as not utlislising any computer viruses to disrupt any part of the GISAID platform. GISAID makes clear there is a `limitation on liablity` and in no event will they be liable on any legal grounds to lost profits, savings, data, the cost of recreating lost data, interruption of business, or costs of procurement of substitute goods or services. Failure to adhere to the intellectual property agreement will lead to `Your rights upon suspension of access` or `Termination`. Although short and in sections rather unhelpful for Data Producers, GISAID does sufficiently implement an IP policy.


#### R3.2 Security of System

GISAID uses a session based authentication, in contrast to token authentication this means a session is created by the server only when a user logged in and in GISAIDs case a session is terminated as soon as the web page is exited or left idle for over an hour. This feature means a base level of security is continuously running for users and data depositors alike when using the platform. More tests could be done the further examine the security of the system, such as Cross-Site Scripting, SQL Injection and URL Manipulation Via HTTP GET Methods; the authors have started to create a traceability matrix for risk and vulnerabilities in the system, this can be accessed on request.

#### R3.3 Security of Content

Currently unknown.

\newpage
## Covid-19 Data Portal

The Covid-19 Data Portal scores considerably worse than GISAID, yet this should be understood as a difference in understanding of openess, not a metric evaluation of right and wrong. The Covid-19 Data Portal does provide numerous sufficient impleneteations for their genome repository and in some cases permits for a more computationally advanced experience when compared to GISAID. 

### Data Responsibility 

#### R1.1 Sufficient Metadata

The Covid-19 Data Portal sufficiently implements a form of stanrdisesd metadata which contains over fifty-five data fields concerning the sequence being submitted. Depending on the service used to download C19DP metadata (see R2.1), metadata can be downloaded through a range of formats, including XML, TSV, CSV and JSON and contains 55 columns (See appendix table 3); in general C19DP metadata includes useful fields such as "Sex", "Host", "Lineage start" and "Lab", all of which missing from GISAID, as well as some less useful such as x,y,z. One could argue, that the C19DP metadata is much messier when compared to GISAID, a large array of the datafields are filled as NA and column values are not categorized to a uniform format, however this mess is most likely the result of the various languages and definitions used among global bioinformaticians and with a minimal data science knowledge one can easily synthesize the data into a more useful and interporatable format. It should also be noted that C19DP provide aggregated metadata on a "Statistics" page, there is much on what can be said with regards to the design of the charts and cartography and much the same for the general usefulness of such simple and highly aggregated metadata.

#### R1.3 Technical Documentation

#### R1.3 Format Control



#### R1.4 Content Control

#### R1.5 Authenticated Provinence

### Service Responsibility

#### R2.1 Reliable Data Services

C19DP provide a REST API, GUI interface and a java bulk downloader CLI tool, this extensive collection of tooling permits users of all abilities to choose a method which they are most comfortable with, however this ease of use also determines the speed and volume in which a user can access data. For example, the GUI interface has a `download` button where it gives the option to download a previosuly defined query or the entire database of genome sequences - in EMBL or FASTA format - or genome sequence metadata - in TSV or as ID's to use with the bulk downloader, while the former works quickly the entrire download option is rather awful, to download the full archive of 4.8 million sequences would take anything from several hours to , with the aid of a super computer or many days while persistently having to have a stable internet connection and not exiting the page. This 'feature' is at best tokenistic as it gives the impression that users without a programming education may have the same data access than someone who does, nonetheless this is a normal feature on open access databases where the target audience is not explicitly programmers. 

For those with a programming education, C19DP provide an API and a bulk downloader CLI to speed up the process of downloading files, both tools operate under a shared infrastructure, being the EBI search API, however the two tools are packaged differently. C19DP API acts as a proxy for the central European Nucleotide Archive, thereby allowing users to efficiently query the database under a structure which fits the Covid-19 Data Portal branding. Likewise with the GUI, the API is still slow to work with, due to the complex environment of the EBI central database the REST API architecture has to circumnavigate many end points that ultimately leads to slower download speeds and a less enjoyable developer experience. The bulk downloader is certainly the most efficient way to download large volumes of data, despite a supposedly scary CLI, the tool allows users to download bulk batches of sequences or metadata in parallel. The tool allows users to form queries in the CLI, given you have the space on your computer users can retrieve tens of giggabytes of sequence data in more formats than GISAID, this being said, when attempting to use this tool to download the entire collection of metadata the tool broke. These issues have been raised with the support team at the EBI yet remained a crucial failure in respoitory responsibslity, with all three tools failing to download the entire metadata it became increasingly difficult to carry out inspections of responsibility classification. Although a solution to access a snapshot of the latest database was offered by the EBI support team, this solution was did not use any of the suggested C19DP data services and instead suggested to directly use the European Nucleotide Archive.

### Legal Responsibility

#### R3.1 Manage IP of Data Producers

#### R3.2 Security of System

#### R3.3 Security of Content


```{r fig3, fig.cap = "Table of Results", echo=FALSE, message=FALSE, warning=FALSE}

r_score1 = data.frame(matrix(ncol = 3, nrow = 10))

r_score_rn = c("Metric", "GISAID: EpiCov", "EBI: Covid-19 Data Platform")
colnames(r_score1) = r_score_rn

metric_col = c(
  # DATA Responsibility
  "R1.1 Sufficent Metadata",
  # metadata which documents the progress of data in the repo to date
  "R1.2 Techincal Documentation",
  # documentation online on how to use data services
  "R1.3 Format Control",
  # uploading data
  "R1.4 Content Control",
  # peer review
  "R1.5 Authenticated Provinence",
  # log in
  # SERVICES Responsibility
  "R2.1 Reliable Data Services",
  # a range of data tools which permit the download of data in various formats
  # LEGAL Responsibility
  "R3.1 Manage IP of Data Producers",
  # legal agreement much can be done
  "R3.2 Security of System",
  # does the system have vulnerabilities
  "R3.3 Security of Content" ,
  # how is content ensured its not reshared ?
  "Total Score"
  
)
r_score1$Metric = metric_col

r_score1$`EBI: Covid-19 Data Platform`[1] = 0.9
r_score1$`EBI: Covid-19 Data Platform`[2] = 0.9
r_score1$`EBI: Covid-19 Data Platform`[3] = 0.9
r_score1$`EBI: Covid-19 Data Platform`[4] = 0.9
r_score1$`EBI: Covid-19 Data Platform`[5] = 0
r_score1$`EBI: Covid-19 Data Platform`[6] = 0.4
r_score1$`EBI: Covid-19 Data Platform`[7] = 0
r_score1$`EBI: Covid-19 Data Platform`[8] = 0.4
r_score1$`EBI: Covid-19 Data Platform`[9] = 0
r_score1$`EBI: Covid-19 Data Platform`[10] = sum(r_score1$`EBI: Covid-19 Data Platform`[1:9])

r_score1$`GISAID: EpiCov`[1] = 0.4
r_score1$`GISAID: EpiCov`[2] = 0.4
r_score1$`GISAID: EpiCov`[3] = 0.9
r_score1$`GISAID: EpiCov`[4] = 0.9
r_score1$`GISAID: EpiCov`[5] = 0.9
r_score1$`GISAID: EpiCov`[6] = 0.9
r_score1$`GISAID: EpiCov`[7] = 0.4
r_score1$`GISAID: EpiCov`[8] = 0.4
r_score1$`GISAID: EpiCov`[9] = 0.9
r_score1$`GISAID: EpiCov`[10] = sum(r_score1$`GISAID: EpiCov`[1:9])


kable(r_score1, caption = "Results", format = "latex")  %>% kable_material_dark() %>%
  kable_styling(latex_options = "HOLD_position")



```



# Discussion

<!-- This paper has presented a novel but highly subject approach  -->
<!-- The RR metric is a novel approach to quantitatively study the responsibility of a data repository, however is   -->

<!--  to truly reflect a robust description of repository responsibility. A multitude of factors were not considered in this analysis, such as  -->
<!-- how practitioners of openness interpret what counts as responsible openness or how community users interact and use each platform. Further work refining the binary metric system may serve as a robust piece of empirical contribution in understanding the general question of responsibility in respotistiores, however only when coupled with qualitative differences.  -->


<!-- (4) suggest that this should be added as a crucial additional factor for R, BUT also that this cannot be easily transformed into a binary metric (1-0) -- we are looking at  -->

<!-- (5) discuss how this works out in case og GISAID vs COVID-19 portal: here we have a clash of ideologies and experiences of what constitutes "good" openness -->

<!-- # Conclusion -->

<!-- (6) conclusion: there is much that CAN be done to metricise and evaluate TRUST principles as a key complement to FAIR, however even such evaluation needs to highlight the unavoidable qualitative/interpretative differences in the implementation of openness -->

# References

<!-- ```{r fig2, fig.cap = "Monthly totals of global SARS-CoV-2 cases sequenced and shared\n on the GISAID and Covid-19 Data Platform database until Febuary 22 2022", echo=FALSE, message=FALSE, warning=FALSE} -->
<!-- source("../code/set-up.r") -->
<!-- main_df = readRDS("../data/main_df.rds") -->
<!-- temporal_sub_all = readRDS("../data/temporal_sub_all.rds") -->
<!-- ggplot(data=temporal_sub_all) + -->
<!--   geom_line(aes(x=Date,y=sum_gisaid, group=1, color='GISAID Monthly Total')) + -->
<!--   geom_line(aes(x=Date,y=sum_cd19dp, group=1, color ='CD19DP Monthly Total')) + -->
<!--   scale_colour_manual("", -->
<!--                       breaks = c("GISAID Monthly Total", "CD19DP Monthly Total"), -->
<!--                       values = c("green", "blue")) + -->
<!--   labs(x = "Date", -->
<!--        y = "Sequence Submissions", -->
<!--        title = "Monthly Total SARS-CoV-2 Sequence Submissions", -->
<!--        caption = "GISAID Metadata: https://www.epicov.org/\nCovid-19 Data Platform Metadata: https://www.ebi.ac.uk/ena/portal/api/ ") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5),   legend.position = "bottom") -->


<!-- ``` -->










